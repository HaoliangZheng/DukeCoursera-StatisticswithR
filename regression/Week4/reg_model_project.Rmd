---
title: "Modeling and prediction for movies"
output: 
  html_document: 
    fig_height: 4
    highlight: pygments
    theme: spacelab
---

## Setup

### Load packages

```{r load-packages, message = FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(statsr)
library(corrplot)
library(GGally)
library(gridExtra)
```

### Load data

```{r load-data}
load("movies.Rdata")
```

* * *

## Part 1: Data

Before starting my research, I need to be familiar with the data set. First I check the codebook, then I explore the data by using the `str()` to investigate the structure.

```{r structure}
str(movies)
```

We can learn that there are 651 movies and 32 variables including both numerical and categorical.

The variable `imdb_rating` is a numerical one, which represents the popularity of a movie, can be our **response variable**. 

For the rest, we need to decide which variables are meaningful and useful to be our **explanatory variables**. 

Some variables are totally irrelevant to the question, such as `title`, `thtr_rel_year(month,day)`, `dvd_rel_year(month,day)`,`imdb_url` and `rt_url`, so we should omit them without hesitation.
Some may be relevant but too difficult to analyze, such as `studio`, `director` and `actor1` through `actor5`, so we have to ignore them for now. With more information or better techniques, we may be able to handle these variables.

To sum up, those irrelevant or difficult ones are omitted, others will be considered to include in our statistical analysis.

* * *

## Part 2: Research question

**My research question:**
Whether there is a linear relationship between imdb rating and a number of other movies' statistics.

It is of interest because imdb rating shows the popularity of one movie and many factors can influence the rating. We want to find out which variables are most useful for us to fit and predict.

This question involves one numerical response variable `imdb_rating` and other numerical or categorical prediction variables. **Multiple regression** will help us answer the question. 

* * *

## Part 3: Exploratory data analysis

First, I need to select useful variables from the original data set and remove the sample containing NA.

```{r data1}
res = c(13)
cat = c(2,3)
num = c(4,14,16,18)
ord = c(5,15,17,19,20,21,22,23,24)

movies1 <-  movies[,c(res,cat,num,ord)]

movies1 <- movies1 %>%
  filter(!is.na(runtime))
```

Then, I'm going to check collinearity and the relationship between response and predictors with *correlation plots*, *generalized pairs plots* and *dide-by-side box plots* below.

**Correlation Plots**

For numerical predictors, I use **Pearson correlation** to measure the degree of those variables correlated. A correlation matrix and a correlation plot are shown below.

```{r corrplot1}
cor(movies1[,4:7])
corrplot(cor(movies1[,4:7]))
```

We can see that `critics_score` and `audience_score` are highly positive correlated, which is quite reasonable. To avoid the collinearity and using 'popularity' to predict 'popularity', we'd better delete `audience_score` variable.


For ordinal predictors, I use **Kendall correlation** to measure the degree of those variables correlated. A correlation matrix and a correlation plot are shown below.

```{r corrplot2}
tep = movies1[,8][[1]]
for(i in 9:16){
  tep <- cbind(tep,movies1[,i][[1]]) 
}

cor(tep,method = "kendall")
corrplot(cor(tep,method = "kendall"))
```

We can see that most pairs of variables have little correlation. Three pais of variables are kind of correlated :`critics_rating` and `audience_rating`, `best_pic_nom` and `best_pic_win`, `best_dir_win` and `best_pic_win`, which is also reasonable. To avoid the collinearity, we'd better delete `audience_rating` and `best_pic_win` variables.

**Generalized Pairs Plots**

To see whether there is association between response variable and other variables, then I use generalized pairs plots.

```{r ggpairs1, warnings=FALSE, message=FALSE, prompt=FALSE, comment=NA}
ggpairs(data = movies1, columns = c(1,2:3))
```

From this graph, we can learn some interesting facts as follow. First, most `title_type` is 'Feature Film', and there shows no strong difference between the averages, indicating that maybe we can get rid of this variable. Second, `genre` seems to be useful because we can see the difference between deifferent genres.

```{r ggpairs2, warnings=FALSE, message=FALSE, prompt=FALSE, comment=NA}
ggpairs(data = movies1, columns = c(1,4:7))
```

From this graph, we can see that `imdb_rating` seems to have positive association with other variables.

**Side-by-side Box Plots**

At last, I use side-by-side box plots also to see whether there is association between response variable and other ordinal variables.

```{r boxplots}
ord_ind = c(8:16)
ord_nam = names(movies1)[ord_ind]

for(i in 1:9){
  temmov <- movies1[,c(1,ord_ind[i])]
  plots <- NULL
  plots <- ggplot(data = temmov, aes_string(x = ord_nam[i], y = 'imdb_rating')) + 
    geom_boxplot() +
    labs(x = names(temmov)[2]) + 
    theme(legend.position='none')
  assign(paste0("plots",i),plots)
}

grid.arrange(plots1, plots2, plots3, plots4, plots5, plots6, plots7, plots8, plots9, nrow=3)
```

From this graph, we can learn some interesting facts as follow. First, for variables `mpaa_rating`, `best_actor_win`, `best_actress_win`, there shows no strong difference between the averages, indicating that maybe we can get rid of these variables. Second, other variables instead show some difference between the averages.


Due to the result in this part, I'd rather delete `title_type`, `mpaa_rating`, `best_actor_win` and `best_actress_win` variables to get a simpler full model.

* * *

## Part 4: Modeling

According to the analysis above, the variables included in the full model are `genre`, `runtime`, `imdb_num_votes`, `critics_score`, `critics_rating`, `best_pic_nom`, `best_dir_win` and `top200_box` these eight variables. 

```{r data2}
movies2 <- movies1
movies2[,c(2,7,8,10,12,13,14)] <- NULL
```

**Full Model**

The data I'm going to use is all in the movies2. Now let's build our **full model** by using the `lm()`.

```{r full model}
lm_full <- lm(imdb_rating ~ . , data = movies2)
summary(lm_full)
```

From the regression table, we can learn lots of interesting facts as follow. First, according to the $F$ test, p-value is extremely small, indicating that my model is kind of effective. Second, some predictors are statistically significant, while others are not, indicating that we really need to do the model selection.

**Model Selection**

For model selection, I choose *backward elimination* with *AIC*, which has been presented in the vedio. To be more specific, $AIC=2k-2\ln(L)$, where $L$ means likelihood. 

With the `step()` function, I can do model selection and see each step easily.

```{r model selection}
lm_aic <-  step(lm_full, direction = "backward")
```

We can see that for each step, AIC is decreasing and one variable is omitted, including `best_dir_win`, `best_pic_nom` and `top200_box`. So only 5 variables are left, forming our final model.

```{r lm_air}
summary(lm_aic)
```

From the regression table of our final model, we can see that all variables are statistically significant(some levels may not).

**Model Diagnostics**

In this step, I'm going to check model conditions using graphs.

- Linearity
- Constant variability

```{r check_linearity}
ggplot(data = lm_aic, aes(x = 1:length(.resid), y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  xlab("Order") +
  ylab("Residuals")
```

We can see that residuals seem to randomly scatter around the dashed line and show no sign of a fan shape. This tells us that everything is all right with these two conditions.

- Nearly normal residuals

```{r check_normal}
ggplot(data = lm_aic, aes(x = .resid)) +
  geom_histogram(binwidth = 0.5) +
  xlab("Residuals")
```

We can see that the graph seem to be symmetric and nearly normal. This tells us that everything is all right with this condition.

**Interpretation**

To interpret model coefficients, we can make some conclusions as follow. 

First, for the variable `genre`, all other factors held even, movies which belong to 'Art House & International', 'Documentary', 'Drama' or 'Musical & Performing Arts' genres are statistically significant more popular than reference level. 

Second, for the variable `runtime`, all other factors held even, movies with more runtime are statistically significant more popular. 

Third, for the variable `imdb_num_votes`, all other factors held even, movies with more number of imdb votes are statistically significant more popular. 

Fourth, for the variable `critics_score`, all other factors held even, movies with higher critics score are statistically significant more popular. 

Fifth, for the variable `critics_rating`, all other factors held even, movies with hifher critics rating are statistically significant more popular. 


* * *

## Part 5: Prediction

The movie I chose to predict is a documentary called **“The Beatles: Eight Days a Week - The Touring Years” (2016)**, whose `imdb_rating` is **7.8**.

First, we need to create a new data frame for this movie.

```{r new_movie}
newmovie <- data.frame(genre = "Documentary", runtime = 106, imdb_num_votes = 10830, critics_score = 96, critics_rating = "Certified Fresh")
```

Then, I can do the prediction using the `predict` function.

```{r new_movie_predict}
predict(lm_aic, newmovie)
```

We can see that my prediction is 7.9, quite close to the true value 7.8. Due to the uncertainty around this prediction, we can also construct a prediction interval.

```{r new_movie_predict_interval}
predict(lm_aic, newmovie, interval = "prediction", level = 0.95)
```

We can see that prediction interval is (6.66,9.16), containing the true value 7.8, which tells us the model is working.

* * *

## Part 6: Conclusion

Through fitting and predicting, we have learned some attributes make a movie popular, which is `genre`, `runtime`, `imdb_num_votes`, `critics_score` and `critics_rating`.

A new movie regarding the Beatles is used to predict, and the result is quite good, which shows that my model performs all right.

When it comes to **shortcomings**, I think some variables may be usefel are omitted due to my lack of ability to handle them. Also, maybe there is non-linear association, and I haven't considered this question.